version: 0.2
env:
  parameter-store:
    # DOCKER_USERNAME: /CodeBuild/Docker/Username
    # DOCKER_PASSWORD: /CodeBuild/Docker/Password
    DOCKER_PAT: /CodeBuild/Docker/PAT

phases:
  install:
    runtime-versions:  #First step is to install the runtime versions which is python in our case.
      python: 3.11
      
  pre_build:
    commands:
      - echo "Pre-Build Phase Started"
      - pip install -r requirements.txt
      #Login To DockerHub If Needed
      #echo "$DOCKERHUB_PASSWORD" | docker login -u "$DOCKERHUB_USERNAME" --password-stdin
      
      #Below is the command we got from "VIEW PUSH COMMANDS" on AWS ECR
      - "aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws/n2p7k0f2"
      
    
  build:
    commands:
      - docker build -t aws-ci-cd-python-flask .
      - docker tag aws-ci-cd-python-flask:latest public.ecr.aws/n2p7k0f2/aws-ci-cd-python-flask:latest

  post_build:
    commands:
      - docker push public.ecr.aws/n2p7k0f2/aws-ci-cd-python-flask:latest

# The artifacts: block in buildspec.yml is essential for CodePipeline because it packages specific files from your CodeBuild environment into a named zip archive stored in S3, which downstream stages like CodeDeploy then download as input artifacts. Without it, your Docker build and ECR push execute perfectly, but CodeDeploy receives an empty artifact (hence "Unable to access the artifact... xvO21ws"), causing deployment failure. The name: BuildArtif creates the exact S3 path structure (CodePipelineVersion4/BuildArtif/[hash]/) that your Deploy stage Input Artifact expects, while files: '**/*' includes all necessary app filesâ€”bridging the gap between build output and deployment.


artifacts:
  files: '**/*'           # Include all files from build directory
  name: BuildArtif        # Exact name CodePipeline Deploy stage expects
